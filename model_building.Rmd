---
title: "Model Building"
author: "Emmett Greenberg, Ted Banken, Ethan McIntosh"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
library(car) # for the vif function to test multicollinearity
library(tidyverse)
```

This script will be where we build & validate our models of ridership.

## Read in and join the data

```{r}
get_dataset <- function(dataset) {
  read.csv(paste0('data/cleaned/stations_routes_', dataset, '.csv'))
}

xfer_station_names <- c('Park Street', 'Downtown Crossing', 'Government Center', 'State')

get_model_data <- function(season) {
  get_dataset(season) %>%
    inner_join(get_dataset(paste(season, 'geog_vars', sep='_')), by=c('route_id', 'parent_station')) %>%
    inner_join(get_dataset(paste(season, 'bus&CR_connections', sep='_')), by=c('route_id', 'parent_station')) %>%
    inner_join(get_dataset(paste(season, 'headways', sep='_')), by=c('route_id', 'parent_station')) %>%
    inner_join(get_dataset(paste(season, 'travel_times_to_cbd', sep='_')), by=c('route_id', 'parent_station')) %>%
    inner_join(get_dataset(paste(season, 'pnr_spaces', sep='_')), by=c('route_id', 'parent_station')) %>%
    inner_join(get_dataset(paste(season, 'walk_scores', sep='_')), by=c('route_id', 'parent_station')) %>%
    inner_join(get_dataset('acs2022_5yr_avgMedianIncome'), by=c('route_id', 'parent_station')) %>%
    inner_join(get_dataset('acs2022_5yr_pop'), by=c('route_id', 'parent_station')) %>%
    inner_join(get_dataset('2021_wac_agg'), by=c('route_id', 'parent_station')) %>%
    inner_join(get_dataset(paste(season, 'colleges', sep='_')), by=c('route_id', 'parent_station')) %>%  
    left_join(get_dataset(paste(season, 'ridership', sep='_')), by=c('route_id', 'parent_station')) %>%
    mutate(transfer = case_when(stop_name %in% xfer_station_names ~ 1, .default=0)) %>%
    mutate(
      #devl_mix = tot_jobs/(tot_pop + tot_jobs), 
      jobs_per_acre = mean_jobs_sqft*43560,
      pop_per_acre = ppsqft*43560, 
      college_students_1000s = college_students/1000,
      connecting_bus_riders_100s = connecting_bus_riders/100,
      median_inc_1000s = avg_median_inc/1000, 
      pnr_spaces_100s = pnr_spaces/100,
      .keep='unused'
      ) %>%
    mutate(route=1, route_id_temp = route_id) %>% # this creates dummy variables for each route
    pivot_wider(names_from='route_id_temp', values_from='route', values_fill=0)
}

model_data_f23 <- get_model_data('f23')
model_data_f19 <- get_model_data('f19')
```

## Descriptive Statistics

```{r}
continuous_vars <- c('avg_boardings', 'avg_headway', 'avg_tt', 'walk_score', 'km_from_cbd', 
                     'median_inc_1000s', 'pop_per_acre', 'jobs_per_acre', 'devl_mix')
sparse_vars <- c('connecting_bus_riders_100s', 'connecting_cr_routes', 'pnr_spaces_100s', 'college_students_1000s')
dummy_vars <- c('Red', 'Orange', 'Green', 'Blue', 'transfer', 'in_bos')


numeric_data <- model_data_f23 %>% select(all_of(c(continuous_vars, sparse_vars)))
summary(numeric_data) # minimum, median, mean, maximum, and interquartile range for each variable
```

For dummy variables (0 or 1), show what number and percent of observations the 1's represent
```{r}
model_data_f23 %>% 
  summarise(across(all_of(dummy_vars), list(num_1s = sum, pct_1s = mean))) %>%
  t()
```

For sparse variables, show what number and percent of observations the 0's represent
```{r}
sum_zeroes <- function(x) {
  sum(x==0)
}

pct_zeroes <- function(x) {
  sum(x==0)/length(x)
}

model_data_f23 %>% 
  summarise(across(all_of(sparse_vars), list(num_0s = sum_zeroes, pct_0s = pct_zeroes))) %>%
  t()
```

Histograms of continuous variables
```{r}
continuous_vars %>% 
  lapply(function(var) hist(
    model_data_f23[[var]], breaks='Sturges', 
    main=paste('Histogram of', var), xlab=paste('Value of', var)
    )) %>% invisible()
```

Histograms of non-zero values for sparse variables (variables with mostly 0s)
```{r}
sparse_vars %>%
  lapply(function(var) hist(
    model_data_f23[[var]] %>% {.[. != 0]}, breaks='Sturges', 
    main=paste('Histogram of', var), xlab=paste('Value of', var)
    )) %>% invisible()
```

Pairs plot
```{r}
model_data_f23 %>% select(all_of(continuous_vars)) %>% pairs()
```

## Model Building

```{r}
# these functions spit out regressions for a given dataframe and dependent variable name,
# specified through a list of named parameters "data" and "y"

base_reg <- function(params) {
  eval(bquote(lm(.(as.symbol(params$y)) ~ #avg_tt + 
       avg_headway + Red + Orange + Blue + transfer #+ km_from_cbd
     + connecting_cr_routes + connecting_bus_routes + pnr_spaces_100s
     + walk_score + median_inc_1000s + pop_per_acre + jobs_per_acre 
     , data=params$data
     )))
}

enhanced_reg <- function(params) { 
  eval(bquote(lm(.(as.symbol(params$y)) ~ #avg_tt + 
       avg_headway + Red + Orange + Blue + transfer #+ km_from_cbd
     + connecting_cr_routes + connecting_bus_routes + pnr_spaces_100s
     + walk_score + median_inc_1000s + pop_per_acre + jobs_per_acre 
     + college_students_1000s
     , data=params$data
     )))
}

specifications <- list(
  "Fall 2019 weekday" = list(data=model_data_f19, y='avg_boardings_wkdy'), 
  "Fall 2023 weekday" = list(data=model_data_f23, y='avg_boardings_wkdy'),
  "Fall 2019 weekday (Boston only)" = list(data=model_data_f19 %>% filter(in_bos == 1), y='avg_boardings_wkdy'),
  "Fall 2023 weekday (Boston only)" = list(data=model_data_f23 %>% filter(in_bos == 1), y='avg_boardings_wkdy'),
  "Fall 2019 weekend" = list(data=model_data_f19, y='avg_boardings_wknd'), 
  "Fall 2023 weekend" = list(data=model_data_f23, y='avg_boardings_wknd'),
  "Fall 2019 weekend (Boston only)" = list(data=model_data_f19 %>% filter(in_bos == 1), y='avg_boardings_wknd'),
  "Fall 2023 weekend (Boston only)" = list(data=model_data_f23 %>% filter(in_bos == 1), y='avg_boardings_wknd')
)

base_regressions <- specifications %>% lapply(base_reg) %>%
  `names<-`(names(.) %>% lapply(function(name) paste(name, "base")))
enhanced_regressions <- specifications %>% lapply(enhanced_reg) %>%
  `names<-`(names(.) %>% lapply(function(name) paste(name, "enhanced")))

regressions <- base_regressions %>% c(enhanced_regressions)
summaries <- regressions %>% lapply(summary)

coefficients <- summaries %>% lapply(function(reg) reg$coefficients)
adj_r2s <- summaries %>% lapply(function(reg) reg$adj.r.squared)
f_stats <- summaries %>% lapply(function(reg) reg$fstatistic)

summaries[['Fall 2023 weekend enhanced']] # display summary for a single specification
```

Calculate the variance inflation factor per variable (to test for multicollinearity) across all models
```{r}
regressions %>% lapply(vif)
```

Create a formatted table for easier comparison across specifications
```{r}
rc <- function(n, digits) round(n, digits) %>% as.character()

format_results <- function(result) {
  result['Estimate'] %>%
    rc(2) %>%
    paste(paste0('(se=', result['Std. Error'] %>% rc(2), ', t=', result['t value'] %>% rc(2), ')'))
}

compare_specifications <- function(var) {
  coefficients %>% 
    lapply(function(df) {
      if (var %in% row.names(df)) format_results(df[var,]) 
      else '--'
    }) %>% 
    as.data.frame()
}

var_names <- coefficients[[length(coefficients)]] %>% row.names() # get variable names from the last model

formatted_output <- var_names %>%
  lapply(compare_specifications) %>%
  bind_rows() %>%
  `row.names<-`(var_names) %>%
  bind_rows(
    adj_r2s %>% lapply(function(ar2) rc(ar2, 3)) %>% as.data.frame() %>% `row.names<-`('Adjusted R Squared'),
    f_stats %>% lapply(function(ar2) rc(ar2, 3)) %>% as.data.frame() %>% `row.names<-`(c('F Statistic', 'df_vars', 'df_obs'))
  )

formatted_output
```

Write the formatted output to csv if we like it
```{r}
formatted_output %>% write.csv('formatted_output.csv', row.names = TRUE)
```


Predicted vs Actual plots

```{r}
plot_y_yhat_w_labels <- function(df, yhat, xy_prefix, add_labels=FALSE) {
  plot(x=df$avg_boardings, y=yhat, pch=16,
       xlab=paste(xy_prefix, 'Actual Boardings'),
       ylab=paste(xy_prefix, 'Predicted Boardings'),
       main=paste(xy_prefix, 'Predicted vs. Actual Boardings by Route-Station'))
  abline(a=0, b=1) # draw 1=1 line for reference
  
  # option to add station labels to help identify the kinds of places we're over- or under-predicting
  if (add_labels) {
    text(x=df$avg_boardings, y=yhat, adj=c(0.5,1), cex=0.5,
       labels=paste0(
         str_sub(df$route_id, end=1),
         '-', str_sub(df$stop_name, end=3))
       )
  }
}
```

```{r}
specifications[['Fall 2023 weekday']]$data %>%
  plot_y_yhat_w_labels(predict(regressions[['Fall 2023 weekday base']]), '')

specifications[['Fall 2023 weekday']]$data %>%
  mutate(avg_boardings = log(avg_boardings)) %>%
  plot_y_yhat_w_labels(predict(regressions[['Fall 2023 weekday base']]) %>% log(), 'Logged')
```

```{r}
specifications[['Fall 2023 weekend']]$data %>%
  plot_y_yhat_w_labels(predict(regressions[['Fall 2023 weekend base']]), '', add_labels=TRUE)

specifications[['Fall 2023 weekend']]$data %>%
  mutate(avg_boardings = log(avg_boardings)) %>%
  plot_y_yhat_w_labels(predict(regressions[['Fall 2023 weekend base']]) %>% log(), 'Logged', add_labels=TRUE)
```

# TODO: actual vs predicted total ridership
# TODO: actual vs predicted map of stations
# TODO: take a preferred specification and do cross-validation 

